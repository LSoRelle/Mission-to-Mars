{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Dependencies \n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Mac Users \n",
    "- trying to be helpful with grading, ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the executable path to driver \n",
    "#executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "#browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Windows Users \n",
    "- because I don't mac =D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the executable path to driver \n",
    "# 'chromedriver.exe'\n",
    "executable_path = {'executable_path': 'C:/Users/39319362/Desktop/SMDA201811DATA2/01-Lesson-Plans/12-Web-Scraping-and-Document-Databases/2/Activities/08-Stu_Splinter/Solved/chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to Code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSight Is the Newest Mars Weather Service\n",
      "By collecting data around the clock, NASA's lander will provide unique science about the Martian surface.\n"
     ]
    }
   ],
   "source": [
    "# NASA Mars News\n",
    "# * Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. \n",
    "#   Assign the text to variables that you can reference later.\n",
    "   \n",
    "# Set url for use in scrape\n",
    "NASA_Mars_url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(NASA_Mars_url)\n",
    "    \n",
    "# Scrape page into Soup\n",
    "soup = bs(browser.html,\"html.parser\")\n",
    "    \n",
    "# Get title and text for latest news based on html tags \n",
    "latest_news = soup.find_all(\"div\",{\"class\":\"list_text\"})[0]\n",
    "    \n",
    "# Store data in a dictionary\n",
    "\n",
    "# Pull the Title and Content apart to make it easier to call in the html\n",
    "news_title = latest_news.find(\"div\",{\"class\":\"content_title\"}).text\n",
    "news_content = latest_news.find(\"div\",{\"class\":\"article_teaser_body\"}).text\n",
    "\n",
    "# Print to verify everything is there\n",
    "print (news_title)\n",
    "print (news_content)\n",
    "\n",
    "# Close the browser after scraping\n",
    "#browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA18905-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# JPL Mars Space Images - Featured Image\n",
    "# * Visit the url for JPL Featured Space Image here.\n",
    "# * Use splinter to navigate the site and find the image url for the current Featured Mars Image \n",
    "#   and assign the url string to a variable called featured_image_url.\n",
    "# * Make sure to find the image url to the full size .jpg image.\n",
    "# * Make sure to save a complete url string for this image.\n",
    "    \n",
    "# Set base url for call back later\n",
    "base_url = 'https://www.jpl.nasa.gov'\n",
    "    \n",
    "# Set url for use in scrape\n",
    "JPL_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(JPL_url)\n",
    "    \n",
    "# Scrape page into Soup\n",
    "soup = bs(browser.html,\"html.parser\")\n",
    "    \n",
    "# Get Featured image based on html tags \n",
    "featured_img = soup.find(\"div\", class_=\"carousel_items\").find(\"article\")\n",
    "    \n",
    "# Create url for featured image\n",
    "featured_img_url = base_url+featured_img['style'].split(':')[1].split('\\'')[1]\n",
    " \n",
    "# Print to verify everything is there\n",
    "print (featured_img_url)\n",
    "    \n",
    "# Close the browser after scraping\n",
    "#browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSight sol 81 (2019-02-17), high -17/2F, low -95/-138F, pressure at 7.23hPa, winds from the WNW at 12 mph gusting to 37.8 mph\n",
      "\n",
      "Welcome to the Mars Weather team @NASAInSight!\n",
      "https://mars.nasa.gov/insight/weather/ …pic.twitter.com/SH12FvcMfv\n"
     ]
    }
   ],
   "source": [
    "# Mars Weather\n",
    "# * Visit the Mars Weather twitter account here and scrape the latest Mars weather tweet from the page. \n",
    "#   Save the tweet text for the weather report as a variable called mars_weather.\n",
    "    \n",
    "# Set url for use in scrape\n",
    "twitter_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(twitter_url)\n",
    "    \n",
    "# Scrape page into Soup\n",
    "soup = bs(browser.html,\"html.parser\")\n",
    "    \n",
    "# Find all elements that contain tweets based on html tags \n",
    "latest_tweets = soup.find_all('div', class_='js-tweet-text-container')\n",
    "    \n",
    "# When I was looking for weather tweets, the first tweet was a retweet not about what I needed\n",
    "# for this project. Spent a lot of time trying to find a way to distinguish retweets and tweets\n",
    "# with weather data, there was not a difference in the html code, so had to write a for loop to\n",
    "# look for the data I did want in the body of a tweet. \n",
    "for tweet in latest_tweets: \n",
    "    weather_tweet = tweet.find('p').text\n",
    "    if 'Sol' and 'high' in weather_tweet:\n",
    "        print(weather_tweet)\n",
    "        break\n",
    "    else: \n",
    "        pass\n",
    "    \n",
    "# Close the browser after scraping\n",
    "#browser.quit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Polar Diameter:</th>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Distance:</th>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Period:</th>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface Temperature:</th>\n",
       "      <td>-153 to 20 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Record:</th>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recorded By:</th>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Value\n",
       "Description                                        \n",
       "Polar Diameter:                            6,752 km\n",
       "Mass:                 6.42 x 10^23 kg (10.7% Earth)\n",
       "Moons:                          2 (Phobos & Deimos)\n",
       "Orbit Distance:            227,943,824 km (1.52 AU)\n",
       "Orbit Period:                  687 days (1.9 years)\n",
       "Surface Temperature:                  -153 to 20 °C\n",
       "First Record:                     2nd millennium BC\n",
       "Recorded By:                   Egyptian astronomers"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mars Facts\n",
    "# * Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the \n",
    "#   planet including Diameter, Mass, etc.\n",
    "# * Use Pandas to convert the data to a HTML table string.\n",
    "\n",
    "# Set url for use in scrape\n",
    "Mars_facts_url = \"https://space-facts.com/mars/\"\n",
    "\n",
    "#Read the html\n",
    "Mars_facts = pd.read_html(Mars_facts_url)\n",
    "\n",
    "# Pull facts in as a Dataframe\n",
    "Mars_facts_df = Mars_facts[0]\n",
    "\n",
    "# Assign columns to the Dataframe\n",
    "Mars_facts_df.columns = [\"Description\",\"Value\"]\n",
    "\n",
    "# Get rid of the id column\n",
    "Mars_facts_df = Mars_facts_df.iloc[1:]\n",
    "Mars_facts_df.set_index(\"Description\", inplace=True)\n",
    "\n",
    "# Show the set to verify everything is there before turning into html \n",
    "Mars_facts_df\n",
    "\n",
    "# Close the browser after scraping\n",
    "#browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">  <tbody>    <tr>      <td>6,752 km</td>    </tr>    <tr>      <td>6.42 x 10^23 kg (10.7% Earth)</td>    </tr>    <tr>      <td>2 (Phobos &amp; Deimos)</td>    </tr>    <tr>      <td>227,943,824 km (1.52 AU)</td>    </tr>    <tr>      <td>687 days (1.9 years)</td>    </tr>    <tr>      <td>-153 to 20 °C</td>    </tr>    <tr>      <td>2nd millennium BC</td>    </tr>    <tr>      <td>Egyptian astronomers</td>    </tr>  </tbody></table>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to html\n",
    "mars_facts_html = Mars_facts_df.to_html(header=False, index=False)\n",
    "\n",
    "# Remove \\n from the code \n",
    "mars_facts_html = mars_facts_html.replace('\\n', '')\n",
    "\n",
    "# Print to verify everything is there\n",
    "mars_facts_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere ', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'title': 'Schiaparelli Hemisphere ', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'title': 'Syrtis Major Hemisphere ', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'title': 'Valles Marineris Hemisphere ', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "# Mars Hemispheres\n",
    "# * Visit the USGS Astrogeology site here to obtain high resolution images for each of Mar's hemispheres.\n",
    "# * You will need to click each of the links to the hemispheres in order to find the image url to the \n",
    "#   full resolution image.\n",
    "# * Save both the image url string for the full resolution hemisphere image, and the Hemisphere title \n",
    "#   containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url \n",
    "#   and title.\n",
    "# * Append the dictionary with the image url string and the hemisphere title to a list. This list will \n",
    "#   contain one dictionary for each hemisphere.\n",
    "\n",
    "# Set base url for call back later\n",
    "base_hemisphere_url = \"https://astrogeology.usgs.gov\"\n",
    "\n",
    "# Set url for use in scrape\n",
    "hemisphere_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(hemisphere_url)\n",
    "\n",
    "# Scrape page into Soup\n",
    "soup = bs(browser.html,\"html.parser\")\n",
    "\n",
    "# Create list for hemisphere url and title\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Find images based on html tags \n",
    "products = soup.find(\"div\", class_ = \"result-list\" )\n",
    "hemispheres = products.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "# for loop to pull each hemisphere into the list\n",
    "for hemisphere in hemispheres:\n",
    "    title = hemisphere.find(\"h3\").text\n",
    "    title = title.replace(\"Enhanced\", \"\")\n",
    "    end_link = hemisphere.find(\"a\")[\"href\"]\n",
    "    image_link = base_hemisphere_url + end_link    \n",
    "    browser.visit(image_link)\n",
    "    soup = bs(browser.html,\"html.parser\")\n",
    "    downloads = soup.find(\"div\", class_=\"downloads\")\n",
    "    image_url = downloads.find(\"a\")[\"href\"]\n",
    "    hemisphere_image_urls.append({\"title\": title, \"img_url\": image_url})\n",
    "\n",
    "# Print to verify everything is there\n",
    "print (hemisphere_image_urls)\n",
    "\n",
    "# Close the browser after scraping\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
